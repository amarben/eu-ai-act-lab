# Lecture 5: AI Governance Framework

Course: EU AI Act Compliance: Build Audit-Ready Documentation
Platform: Udemy
Duration: 25-30 minutes
Section Type: Main Content (3 slides)

---

## Slide 1: Step Overview

### Slide Title
"Building Your AI Governance Foundation: Structure, Policies, and Accountability"

### Slide Notes (Instructor Narration - 340 words)

Governance is the organizational backbone of EU AI Act compliance, and without it, even the best technical implementations will fail regulatory scrutiny. When auditors and regulators evaluate your AI system, they're not just looking at algorithms and documentation—they're examining whether you have established clear organizational structures, defined roles and responsibilities, formal policies and procedures, accountability mechanisms, and oversight frameworks that ensure compliance isn't accidental but systematic and sustainable. Strong AI governance transforms compliance from a checkbox exercise into an embedded organizational capability where everyone knows their responsibilities, decisions follow documented processes, risks are escalated appropriately, and accountability is crystal clear at every level.

The EU AI Act doesn't prescribe a specific governance model because organizations vary enormously in size, structure, and complexity, but it does require demonstrable governance that addresses specific regulatory obligations. You must identify who is responsible for risk management, data governance, technical documentation, human oversight, incident management, and regulatory reporting. You must establish policies that define how AI systems are developed, deployed, monitored, and retired. You must create decision-making frameworks that determine who approves high-risk AI deployments, who investigates incidents, who communicates with regulators, and who ensures continuous compliance monitoring. Without this structure, compliance activities become fragmented across teams, critical requirements fall through cracks, accountability becomes diffuse, and organizations cannot demonstrate systematic compliance during audits.

Effective AI governance includes several essential components working together as an integrated system. First, you need an AI governance committee or working group with executive sponsorship, cross-functional representation, and clear decision-making authority. Second, you require formal policies covering AI development lifecycle, risk management, data governance, transparency, human oversight, and incident response. Third, you must define specific roles with documented responsibilities—who is the AI system owner, who manages compliance, who conducts risk assessments, who maintains documentation, and who interfaces with regulators. Fourth, you need accountability mechanisms including approval workflows, escalation procedures, compliance monitoring, and audit trails. Finally, you require governance documentation that proves to regulators that your compliance isn't improvised but follows established organizational processes with clear ownership and oversight at every step.

### Bullet Points

- Organizational structure for systematic AI Act compliance
- Defines roles, responsibilities, and accountability mechanisms
- Establishes formal policies for AI lifecycle management
- Creates decision-making frameworks and approval workflows
- Ensures compliance is embedded, not ad-hoc
- Provides audit trail proving systematic governance
- Includes committee structure with executive sponsorship
- Integrates risk management, data governance, and oversight

---

## Slide 2: Real-World Application

### Slide Title
"AI Governance in Practice: Roles, Policies, and Organizational Design"

### Slide Notes (Instructor Narration - 335 words)

Let's examine how organizations implement AI governance by walking through a realistic scenario showing the governance structures, roles, and policies that make EU AI Act compliance sustainable and auditable. Understanding these practical implementations helps you design governance appropriate for your organization's size and complexity.

Consider FinServe Analytics, a financial technology company operating multiple AI systems for credit scoring, fraud detection, and customer service automation. After completing their gap assessment, they realized their biggest deficiency wasn't technical capability but organizational structure—no one had clear ownership of compliance, policies existed only in email threads, and decision-making about AI deployments was informal and undocumented. They decided to establish formal AI governance following EU AI Act requirements.

They created an AI Governance Committee chaired by their Chief Risk Officer with members from legal, engineering, data science, product management, and compliance functions. This committee meets monthly to review new AI systems, approve high-risk deployments, assess compliance status, investigate incidents, and make policy decisions. They documented the committee charter specifying decision-making authority, escalation procedures, and reporting lines to the executive team and board of directors. Critically, they assigned a dedicated AI Compliance Manager reporting to the Chief Risk Officer with full-time responsibility for EU AI Act compliance across all systems. This person isn't just coordinating—they have authority to block deployments that don't meet compliance standards.

For policies, they developed six core governance documents. Their AI Development Policy defines mandatory stages for high-risk systems including risk assessment, data governance review, technical documentation, human oversight design, and compliance approval before deployment. Their Risk Management Policy establishes the framework for identifying, assessing, mitigating, and monitoring risks throughout the AI lifecycle. Their Data Governance Policy specifies requirements for training data quality, bias testing, data lineage, and documentation standards. Their Incident Response Policy defines what constitutes an AI incident, reporting procedures, investigation requirements, and regulatory notification timelines. Their Human Oversight Policy establishes oversight requirements based on risk classification with specific procedures for human intervention capabilities. Finally, their AI Transparency Policy defines disclosure requirements for systems interacting with users or making significant decisions affecting individuals.

### AI Governance Structure Example

| Governance Component | FinServe Analytics Implementation | Key Responsibilities | Documentation |
|---------------------|----------------------------------|---------------------|---------------|
| AI Governance Committee | Monthly meetings, CRO chair, cross-functional | Approve deployments, policy decisions, incident review | Committee charter, meeting minutes |
| AI Compliance Manager | Full-time role, reports to CRO | Coordinate compliance, maintain documentation, audit liaison | Role description, authority matrix |
| AI System Owners | Product managers for each system | Day-to-day compliance, risk management, documentation | Ownership assignment matrix |
| Data Governance Lead | Senior data engineer | Data quality, bias testing, lineage tracking | Data governance policies |
| Risk Management Lead | Chief Risk Officer | Risk framework, assessment oversight, mitigation | Risk management framework |
| Technical Documentation Lead | Engineering manager | Architecture docs, model cards, technical specs | Documentation standards |
| Human Oversight Coordinator | Product operations manager | Oversight procedures, training, monitoring | Oversight policies and procedures |
| Incident Response Team | Cross-functional on-call rotation | Incident investigation, remediation, reporting | Incident response playbook |

### Essential Governance Policies

**AI Development Policy**
- Mandatory stages for high-risk systems
- Risk assessment and approval gates
- Documentation requirements at each stage
- Deployment authorization procedures
- Post-deployment monitoring obligations

**Risk Management Policy**
- Risk identification methodology
- Risk assessment criteria and frequency
- Mitigation measure requirements
- Risk acceptance authority levels
- Continuous monitoring procedures

**Data Governance Policy**
- Training data quality standards
- Bias detection and testing requirements
- Data lineage and traceability
- Data governance documentation
- Data retention and deletion procedures

**Incident Response Policy**
- Incident definition and classification
- Reporting and escalation procedures
- Investigation and root cause analysis
- Remediation and corrective actions
- Regulatory notification requirements

**Human Oversight Policy**
- Oversight requirements by risk tier
- Human intervention capabilities
- Oversight personnel training
- Monitoring and evaluation procedures
- Override and escalation mechanisms

**Transparency Policy**
- User disclosure requirements
- Information provision mechanisms
- Communication standards and templates
- Transparency documentation
- User feedback and complaint procedures

---

## Slide 3: Practical Application

### Slide Title
"Governance Framework in Practice: Building Organizational Accountability"

### Slide Notes (Practical Application Narration - 500 words)

Now let's walk through exactly how a company establishes their AI governance framework with concrete structures, specific role assignments, and formal policies that demonstrate systematic compliance. We'll follow TalentTech Solutions as they build their organizational foundation for managing their high-risk AI Recruitment Assistant, documenting every governance element with actual names, responsibilities, and authority levels that auditors expect to see.

TalentTech begins by establishing their AI Governance Committee as the formal governing body with executive sponsorship and cross-functional representation. They document: "Committee Name: AI Governance Committee, Committee Chair: Rachel Thompson (Chief Risk Officer), Justification: Risk oversight central to AI Act compliance requires C-level authority and direct reporting to CEO. Committee Members: (1) David Chen, General Counsel—responsible for regulatory interpretation, legal risk assessment, and communication with regulatory authorities; (2) Sarah Chen, Chief Technology Officer—responsible for technical feasibility assessment, architecture review, and engineering resource allocation; (3) Michael Rodriguez, Data Engineering Lead—responsible for data governance, bias testing methodology, and dataset quality oversight; (4) Lisa Park, Head of Product—responsible for user impact assessment, business requirements validation, and stakeholder communication; (5) Jennifer Martinez, Compliance Manager—responsible for documentation coordination, audit preparation, and regulatory monitoring. Meeting Frequency: Monthly recurring meeting, second Tuesday of each month, with emergency meetings convened as needed for critical incidents or deployment decisions. Decision-Making Authority: Approve/reject high-risk AI system deployments, review and approve governance policies and significant policy changes, investigate and authorize response to serious incidents, authorize communications with market surveillance authorities, allocate compliance budget and resources, escalate critical issues to CEO and Board Risk Committee."

They document their committee charter: "Purpose: The AI Governance Committee provides executive oversight of all high-risk AI systems deployed by TalentTech Solutions, ensuring EU AI Act compliance through systematic risk management, policy enforcement, and continuous monitoring. Scope: All high-risk AI systems as defined by Annex III, with particular focus on employment-related AI systems covered by our recruitment platform. Authority: Committee has authority to block system deployments that fail compliance requirements, mandate remediation activities, investigate incidents, and authorize regulatory communications. Reporting: Committee reports monthly to CEO and quarterly to Board Risk Committee, with immediate escalation for serious incidents or material compliance issues. Charter approved by CEO May 15, 2024, next review date May 15, 2025."

TalentTech then defines specific role assignments with clear accountability. They document: "Role: AI Compliance Manager (Full-Time Dedicated), Assigned To: Jennifer Martinez (jennifer.martinez@talenttech.com), Responsibilities: (1) Maintain complete compliance documentation for all high-risk AI systems with version control and audit trails, (2) Coordinate quarterly gap assessments and track remediation progress, (3) Prepare for regulatory inspections including evidence compilation and interview coordination, (4) Serve as primary liaison with market surveillance authorities for compliance inquiries, (5) Monitor EU AI Act guidance documents and regulatory developments, distribute summaries to governance committee, (6) Coordinate conformity assessment activities with notified bodies. Authority: Block deployments of non-compliant systems pending governance committee review, request documentation and evidence from any team member, attend all technical design reviews for high-risk systems, escalate compliance concerns directly to CRO. Accountability: Reports to Chief Risk Officer with quarterly performance reviews assessing documentation quality, audit readiness, and regulatory relationship management."

Additional role assignments include: "Role: AI System Owner (Recruitment Platform), Assigned To: Lisa Park, Responsibilities: Day-to-day compliance for recruitment AI including human oversight effectiveness, incident reporting, user complaint handling. Authority: Approve routine updates that don't change system behavior, mandatory sign-off for substantial modifications. Role: Data Governance Lead, Assigned To: Michael Rodriguez, Responsibilities: Enforce data quality standards, conduct bias testing per documented methodology, maintain data lineage documentation. Authority: Reject training datasets that fail quality criteria, mandate bias remediation before deployment. Role: Risk Management Lead, Assigned To: Rachel Thompson (CRO), Responsibilities: Maintain enterprise risk register, oversee risk assessment methodology, ensure mitigation measures implemented. Authority: Require risk reassessment for system modifications, mandate additional controls for high residual risks."

Finally, TalentTech establishes six core governance policies with version control and approval records. For their AI Development Policy, they document: "AI Development Policy v1.0, Effective Date: May 20, 2024, Policy Owner: Sarah Chen (CTO), Approval Authority: AI Governance Committee (approved May 14, 2024), Next Review: November 20, 2024. Purpose: This policy establishes mandatory development stages, approval gates, and technical requirements for all high-risk AI systems to ensure EU AI Act compliance from design through deployment. Scope: Applies to all high-risk AI systems per Annex III classification. Key Requirements: (1) Mandatory risk assessment before development initiation, (2) Data governance sign-off before training, (3) Bias testing with documented thresholds before validation, (4) Human oversight design review before user testing, (5) Technical documentation completion before deployment, (6) Governance committee approval before production release. Enforcement: System deployments blocked by DevOps pipeline without documented approval at each gate."

They document similar detailed policies for Risk Management Policy, Data Governance Policy, Incident Response Policy, Human Oversight Policy, and Transparency Policy, each with specific requirements, approval records, version control, and responsible owners. This comprehensive governance framework proves to auditors that TalentTech has embedded EU AI Act compliance into their organizational structure with clear executive sponsorship, cross-functional coordination, formal policies, and systematic oversight mechanisms that ensure sustainable compliance beyond any individual project or person.

### Bullet Points

- Governance committee with C-level chair and cross-functional membership documented with specific names and contact information
- Committee charter defining purpose, scope, authority, reporting lines, and board oversight with formal approval dates
- Meeting frequency and decision-making authority including deployment approval, policy review, incident response, and resource allocation
- Specific role assignments with full name, contact, detailed responsibilities, authority levels, and accountability mechanisms
- AI Compliance Manager as dedicated full-time role with authority to block non-compliant deployments
- Six core governance policies with version control, effective dates, policy owners, approval authority, and review schedules
- Policy enforcement mechanisms integrated into technical processes like DevOps deployment gates
- Comprehensive governance documentation package proving embedded organizational capability for systematic compliance

---

## Practice Assignment

### Title
Design Comprehensive AI Governance Framework for Your Organization

### Description
Establish your AI governance committee, define specific role assignments with authority levels, create six core governance policies with version control, and document your complete governance framework proving systematic organizational capability for EU AI Act compliance.

### Estimated Duration
35-40 minutes

### Instructions

Task 1: Establish Governance Committee with Executive Sponsorship

Create detailed documentation for your AI Governance Committee structure. Identify who will chair this committee—select a C-level executive with risk, compliance, or technology responsibility who has authority to allocate resources and escalate to board level. Document their full name, title, email, and justification for why this person is appropriate (consider their existing authority, regulatory experience, and organizational influence). Identify 4-6 cross-functional committee members representing legal, engineering, data science, product, and compliance functions. For each member, document: (1) Full name and title, (2) Department and contact information, (3) Specific governance responsibility (e.g., "responsible for regulatory interpretation and legal risk assessment"), (4) Subject matter expertise they bring to committee deliberations. Define meeting frequency realistically—monthly for mature organizations, bi-weekly during initial compliance implementation. Document decision-making authority with specific examples: "Authority to approve/reject high-risk AI system deployments, review and approve governance policies and significant changes, investigate and authorize response to serious incidents, authorize communications with market surveillance authorities, allocate compliance budget up to €X without additional approval, escalate critical issues to CEO and Board Risk Committee." Draft a comprehensive committee charter (200-300 words) covering: Purpose explaining why committee exists, Scope defining which AI systems fall under committee oversight, Authority specifying what decisions committee can make independently, Reporting structure showing committee reports to CEO monthly and Board quarterly, Approval documentation showing "Charter approved by [CEO name] on [date], next review date [6 months later]."

Task 2: Define Roles and Responsibilities with Clear Accountability

Create specific role assignments for all governance functions with named individuals and documented authority. Start with AI Compliance Manager role—identify a specific person (full name and contact) who will coordinate EU AI Act compliance. If you don't have a dedicated compliance person, assign this to someone with sufficient seniority and time allocation (minimum 20-40% FTE for high-risk systems). Document detailed responsibilities: (1) Maintain complete compliance documentation with version control, (2) Coordinate quarterly gap assessments and track remediation, (3) Prepare for regulatory inspections, (4) Serve as primary liaison with authorities, (5) Monitor regulatory developments, (6) Coordinate conformity assessment activities. Critical: Document their authority explicitly—"Authority to block deployments of non-compliant systems pending committee review, request documentation from any team member, attend all design reviews, escalate concerns directly to CRO." Assign AI System Owner role to the product manager or technical lead responsible for each high-risk system, documenting their day-to-day compliance accountability including oversight effectiveness, incident reporting, and user complaint handling. Designate Data Governance Lead (typically senior data engineer or Chief Data Officer) with authority to reject datasets failing quality criteria and mandate bias remediation. Assign Risk Management Lead (CRO or designated risk manager) responsible for risk register maintenance and mitigation oversight. For every role, document: name, contact, responsibilities (numbered list), authority (specific decisions they can make), accountability (who they report to and how performance is measured).

Task 3: Create Six Core Governance Policies with Regulatory Mapping

Develop comprehensive governance policies addressing all EU AI Act requirements with version control and approval documentation. For each policy, create a structured document containing: (1) Policy title and version (e.g., "AI Development Policy v1.0"), (2) Effective date and next review date (6-12 months), (3) Policy owner name and title, (4) Approval authority documentation (e.g., "Approved by AI Governance Committee on May 14, 2024"), (5) Purpose statement explaining why policy exists and what it addresses, (6) Scope defining which systems and situations policy applies to, (7) Key requirements as numbered list of mandatory actions with responsible parties, (8) Enforcement mechanisms explaining how policy compliance is verified and violations handled. Create these six policies: AI Development Policy (covering mandatory development stages from requirements through deployment with approval gates at each stage, addressing Articles 9-15), Risk Management Policy (establishing risk identification, assessment, mitigation, and monitoring framework per Article 9), Data Governance Policy (defining data quality standards, bias testing methodology with statistical thresholds, data lineage requirements per Article 10), Incident Response Policy (defining serious incident classification criteria, notification timeframes, investigation procedures, corrective action requirements per Article 73), Human Oversight Policy (establishing oversight measures, personnel training requirements, intervention capabilities, effectiveness monitoring per Article 14), Transparency Policy (specifying user disclosure requirements, information provision mechanisms, documentation of system capabilities and limitations per Article 13). Each policy should be 2-3 pages with specific, actionable requirements that could be audited.

Task 4: Document Policy Approval Workflow and Version Control

For each of the six governance policies, establish formal approval and maintenance processes that prove these are living documents, not one-time drafts. Document approval workflow: "Drafted by [role/name], Reviewed by [list all reviewers with roles], Approved by [approval authority—typically governance committee or C-level executive] on [specific date], Effective date [when policy takes effect], Distribution list [who receives policy and must acknowledge receipt]." Establish version control system: "Current Version: 1.0, Previous Versions: None (initial release), Version History: Document all future changes with date, change description, approver, and rationale." Specify review schedule: "Next scheduled review: [6-12 months from effective date], Review trigger events: Significant regulatory guidance changes, serious incident requiring policy update, organizational restructuring affecting responsibilities, audit findings identifying policy gaps." Designate policy owner: "Policy Owner: [specific name and title], Owner Responsibilities: Monitor policy effectiveness through compliance metrics, update policy when needed, ensure stakeholder training on policy requirements, report policy violations to governance committee." Create acknowledgment mechanism: "All personnel involved in high-risk AI development must acknowledge receipt and understanding of relevant policies annually, documented in [training system/HR system]." This documentation proves your policies are formally approved, actively maintained, and embedded in organizational processes.

Task 5: Compile Comprehensive Governance Documentation Package

Assemble all governance components into a professional documentation package demonstrating embedded organizational capability. Your package should contain: (1) Executive Summary (1 page) explaining how your governance framework systematically addresses EU AI Act requirements with specific references to Articles 17 (quality management system), Article 9 (risk management), Article 26 (post-market monitoring); (2) Governance Committee Charter with complete membership list, authority documentation, meeting schedule, and board reporting procedures; (3) Organizational Chart showing governance committee, all role assignments, reporting relationships, and integration with existing organizational structure; (4) Roles and Responsibilities Matrix in table format with columns: Role Title, Assigned Person, Contact, Key Responsibilities, Authority Level, Accountability Mechanism; (5) Six Core Governance Policies each formatted consistently with version control, approval documentation, and enforcement mechanisms; (6) Implementation Roadmap showing policy rollout timeline, training schedule, first committee meeting date, and compliance milestones; (7) Metrics Dashboard template defining how you'll measure governance effectiveness (committee meeting frequency achieved, policy violation count, audit finding count, time to incident resolution). This comprehensive package—typically 20-30 pages total—proves to auditors that your compliance is not dependent on individual heroics but embedded in organizational structure with executive sponsorship, clear ownership, formal policies, and systematic oversight.

### Deliverable

AI Governance Framework Documentation Package (20-30 pages) containing:
1. Executive summary mapping governance framework to EU AI Act requirements
2. Governance committee charter with membership, authority, and approval documentation
3. Organizational chart showing governance structure and reporting lines
4. Roles and responsibilities matrix with specific names, contacts, responsibilities, authority levels, and accountability mechanisms
5. Six core governance policies with version control, approval records, and enforcement mechanisms
6. Implementation roadmap with training schedule and compliance milestones
7. Governance effectiveness metrics and monitoring dashboard template

### Discussion Questions

Post in the course discussion board:
- Who will chair your AI Governance Committee and what specific authority do they have to enforce compliance?
- What was the most challenging aspect of defining roles—finding the right people or defining appropriate authority levels?
- Which governance policy required the most customization to fit your organization's existing processes?
- How does your AI governance framework integrate with existing risk, security, or quality management structures?
- What resources (budget, headcount, tools) do your governance roles need to be effective?  What's your biggest resource gap?
- How will you measure whether your governance framework is actually working? What metrics will you track?

---

## Downloadable Resources

Included with This Lecture:

1. AI Governance Committee Charter Template (PDF) - Formal charter structure with authority documentation
2. Roles and Responsibilities Matrix Template (PDF) - RACI matrix for AI governance functions
3. Six Core Governance Policies Template Package (PDF) - Complete policy templates with regulatory citations
4. Governance Policy Approval Workflow Guide (PDF) - How to formalize policy approval and version control
5. Governance Maturity Assessment (PDF) - Evaluate your governance effectiveness over time

---

## Key Takeaways

- AI governance provides organizational backbone for systematic EU AI Act compliance
- Governance committee requires executive sponsorship and cross-functional membership
- Clear role assignments with documented authority prevent accountability gaps
- Six core policies address development, risk, data, incidents, oversight, and transparency
- Formal approval and version control demonstrate policies are operational
- Governance documentation proves compliance is embedded organizational capability
- Effective governance makes all other compliance activities sustainable and auditable

---

## Instructor Notes

### Setup Before Lecture
- Ensure Governance Module is fully functional in Implementation Lab
- Prepare governance examples for different organization sizes
- Review industry governance frameworks and best practices
- Load realistic role assignment scenarios

### Key Emphasis Points
- Governance must have real authority, not just coordination responsibility
- Executive sponsorship is critical for governance effectiveness
- Policies must be formally approved and maintained with version control
- Roles should be specific people, not just generic job titles
- Governance documentation is audit evidence proving systematic compliance
- Governance framework should integrate with existing organizational structures
- Small organizations can have simpler governance but same core components

### Common Student Questions

Q: "Our organization is small with only ten people. Do we really need a formal governance committee?"
A: Yes, but scaled appropriately. Even small organizations need clear governance, but your committee might be three people meeting quarterly rather than eight people meeting monthly. What matters is documented structure with clear roles, policies, and decision-making authority—not the size or formality of the structure. A three-person governance team with clear responsibilities and documented policies satisfies regulatory requirements.

Q: "We already have a Data Governance Committee and a Risk Management Committee. Do we need a separate AI Governance Committee?"
A: Not necessarily. You can designate an existing committee as your AI governance body if you expand its charter to cover AI Act requirements, add necessary cross-functional members, and document the expanded scope. Avoid creating redundant committees. What regulators want to see is clear governance with documented authority, not multiple committees.

Q: "Can the same person hold multiple governance roles like AI Compliance Manager and Data Governance Lead?"
A: In smaller organizations, yes, one person can hold multiple roles as long as you clearly document each role's distinct responsibilities. What you cannot do is have undefined or vague accountability. Document that Jane Smith serves as both AI Compliance Manager and Data Governance Lead with specific responsibilities for each role clearly articulated.

Q: "How do we get executive buy-in for creating formal AI governance when leadership sees it as bureaucracy?"
A: Frame governance in risk and liability terms. Explain that without clear governance, the organization has no defensible position during regulatory audits, no systematic approach to preventing compliance failures, and no clear accountability when incidents occur. Show executives that governance isn't bureaucracy—it's risk management and liability protection. Emphasize that regulators will ask "who is responsible for compliance" and "show us your governance documentation" during audits.

Q: "Can we use AI-generated policies or must we write them ourselves?"
A: You can use templates, frameworks, or AI-generated starting points, but you must customize them for your organization, have appropriate stakeholders review them, obtain formal approval from authorized decision-makers, and implement them operationally. Regulators don't care how policies originated—they care that policies are appropriate for your context, formally approved, and actually followed.

### Transition to Next Lecture

"Excellent work establishing your AI governance framework! You now have the organizational foundation with clear roles, policies, and accountability mechanisms that make EU AI Act compliance sustainable. In our next lecture, we'll implement one of the most critical high-risk requirements: the risk management system required by Article 9. You'll learn how to identify risks systematically, assess their severity, implement mitigation measures, and maintain continuous risk monitoring throughout your AI system's lifecycle. See you in the next lecture!"

---

Lecture created strictly following course-creator skill standards: 3-slide main content section, 300-350 word slide notes, 500-word video demo, connected narrative paragraphs, 6-8 word bullet points, no bold labels, plain text format.
